# Project-Luca

Project-Luca is an open-source initiative dedicated to creating highly efficient artificial intelligence. The objective is not to chase scale for its own sake, but to build systems that operate at maximum intelligence per parameter. Every detail—from the architecture to the dataset—is tuned to achieve the balance point where the model generates coherent, stable tokens without wasted compute. Techniques considered “old” are revisited, fine-tuned, and optimized, proving that true efficiency does not always require novelty but refinement.

The development path has been gradual but deliberate. The earliest version, Luca Nano-n1 (v1), was trained on just 160 KB of data. The follow-up, Luca Nano-n1.5 (v1.5), scaled to ~14 MB—imperfect but an important step forward. Now, the next generation, Luca Nano-n2, is being prepared with a curated 1 GB dataset: approximately 450 MB of science and English language data to provide structural and reasoning capability, with the remaining data focused on knowledge density and learning patterns to give the model deeper intelligence.

All code, datasets, models, and architectural details are fully open source. Everything can be downloaded, studied, fine-tuned, or repurposed without restriction. The project is trained on accessible consumer hardware (Intel i5-12450H CPU, NVIDIA RTX 3050 4GB GPU), demonstrating that meaningful AI research does not require industrial-scale clusters.

⚠️ Model Status: Luca Nano-n1 and Nano-n1.5 should be treated strictly as experimental. They hallucinate heavily and are not suitable for reliable tasks. The first stable release, Luca Nano-n2, is scheduled for release in mid-October, and it represents a significant leap forward in reliability and efficiency.

The broader vision behind Project-Luca is driven by two ultimate goals. The first is to build a cutting-edge AI system for chemistry, with a special focus on cosmetics, capable of generating advanced formulations that surpass the work of any known model or human expert. The second is to develop technology that links a human neural network to an artificial neural network, enabling near-direct exchange of weights with almost no conversion or latency—far beyond the current state of the art in brain–computer interfaces. One of the core reasons for building these AI models is to collect and process inhuman volumes of data, paving the way for breakthroughs that demand scale no individual human could handle.

Project-Luca is therefore more than an experiment in model training. It is a foundation for efficient intelligence, a proof of what can be achieved with limited hardware and open access, and a step toward merging human and artificial cognition into a single continuum of thought.

